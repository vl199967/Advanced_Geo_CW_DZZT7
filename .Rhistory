type(y)
y.type()
y.type
x <- spatial.data[,c(10,11)]
e <- spatial.data$ExpectedNum
y <- spatial.data$Number_of_EV_Fire
stan.spatial.dataset <- list(N=n, N_edges=n_edges, node1=nod1, node2=nod2, Y=y, X=x, K=length(x), Offset=e)
icar_poisson_fit = stan("stan.stan", data=stan.spatial.dataset, iter=10000, control = list(max_treedepth = 12), chains=6, verbose = FALSE)
View(spatial.data)
View(stan.spatial.dataset)
View(stan.spatial.dataset)
View(stan.spatial.dataset)
View(spatial.data)
numeric_vector <- as.numeric(unlist(stan.spatial.dataset))
View(Traffic_boro)
Traffic_boro <- read.csv(here::here("traffic-flow-boro.csv"))
col_indices <- c(32)
col_names <- names(Traffic_boro)[col_indices]
View(Traffic_boro)
Traffic_boro <- Traffic_boro %>% select(all_of(c(col_names, "Local.Authority"))) %>%  slice(2:34) %>% mutate(Local.Authority = toupper(Local.Authority)) ## First row empty. Rows after 34th were data for other regions in England.
View(Traffic_boro)
vehicles_boro <- read.csv(here::here("vehicles-per-boro.csv"))  %>% select(Area, PLG.Total) %>%  slice(2:34) %>% mutate(Area = toupper(Area))
# 2020 London population by borough. We need population data to calculate the expected number of EV Fire accidents per borough
#In order to estimate the risk of Fire incidents caused by EVs at the borough level in London
#we will need to first obtain a column that contains estimates from expected number of EV-caused fire accidents.
#This is derived from the Population column which as denominators or reference population size which is multiplied to the raw count of EV Fire incidents to get the number of expected casualties for each London borough.
pop <- read.csv(here::here("Dataset for Week 8","Dataset for Week 8","Road Casualties Data 2015-2020.csv")) %>% slice(275:307) %>% mutate(LAD21NM = toupper(LAD21NM)) %>% select(LAD21NM,Population)
pop_plus_accident <- merge(pop, EV_Fire_Boro, by.x = "LAD21NM", by.y = "IncGeo_BoroughName", all.x = TRUE)
# calculate the expected number of cases
pop_plus_accident$ExpectedNum <- round(expected(population = pop_plus_accident$Population, cases = pop_plus_accident$count, n.strata = 1), 0)
#merge traffic flow, vehicle registered with pop_plus_accident
pop_plus_accident <- merge(pop_plus_accident, Traffic_boro, by.x = "LAD21NM", by.y = "Local.Authority", all.x = TRUE)
pop_plus_accident <- merge(pop_plus_accident, vehicles_boro, by.x = "LAD21NM", by.y = "Area", all.x = TRUE)
pop_plus_accident <- pop_plus_accident %>%   rename(Borough = LAD21NM, Number_of_EV_Fire = count, Total_vehicles = PLG.Total, Traffic_volume = col_names) # rename the columns to things that make more sense
vehicles_boro <- read.csv(here::here("vehicles-per-boro.csv"))  %>% select(Area, PLG.Total) %>%  slice(2:34) %>% mutate(Area = toupper(Area))
# 2020 London population by borough. We need population data to calculate the expected number of EV Fire accidents per borough
#In order to estimate the risk of Fire incidents caused by EVs at the borough level in London
#we will need to first obtain a column that contains estimates from expected number of EV-caused fire accidents.
#This is derived from the Population column which as denominators or reference population size which is multiplied to the raw count of EV Fire incidents to get the number of expected casualties for each London borough.
pop <- read.csv(here::here("Dataset for Week 8","Dataset for Week 8","Road Casualties Data 2015-2020.csv")) %>% slice(275:307) %>% mutate(LAD21NM = toupper(LAD21NM)) %>% select(LAD21NM,Population)
pop_plus_accident <- merge(pop, EV_Fire_Boro, by.x = "LAD21NM", by.y = "IncGeo_BoroughName", all.x = TRUE)
# calculate the expected number of cases
pop_plus_accident$ExpectedNum <- round(expected(population = pop_plus_accident$Population, cases = pop_plus_accident$count, n.strata = 1), 0)
#merge traffic flow, vehicle registered with pop_plus_accident
pop_plus_accident <- merge(pop_plus_accident, Traffic_boro, by.x = "LAD21NM", by.y = "Local.Authority", all.x = TRUE)
pop_plus_accident <- merge(pop_plus_accident, vehicles_boro, by.x = "LAD21NM", by.y = "Area", all.x = TRUE)
pop_plus_accident <- pop_plus_accident %>%   rename(Borough = LAD21NM, Number_of_EV_Fire = count, Total_vehicles = PLG.Total, Traffic_volume = col_names) # rename the columns to things that make more sense
View(pop_plus_accident)
# merge the attribute table to the shapefile
spatial.data <- merge(London_boro_shp, pop_plus_accident, by.x = "Borough", by.y = "Borough", all.x = TRUE)
# need to be coerced into a spatial object
sp.object <- as(spatial.data, "Spatial")
# needs to be coerced into a matrix object
adjacencyMatrix <- shape2mat(sp.object)
# we extract the components for the ICAR model
extractComponents <- prep_icar_data(adjacencyMatrix)
n <- as.numeric(extractComponents$group_size)
nod1 <- extractComponents$node1
nod2 <- extractComponents$node2
n_edges <- as.numeric(extractComponents$n_edges)
y <- spatial.data$Number_of_EV_Fire
x <- spatial.data[,c(10,11)]
e <- spatial.data$ExpectedNum
View(spatial.data)
stan.spatial.dataset <- list(N=n, N_edges=n_edges, node1=nod1, node2=nod2, Y=y, X=x, K=length(x), Offset=e)
View(stan.spatial.dataset)
icar_poisson_fit = stan("stan.stan", data=stan.spatial.dataset, iter=10000, control = list(max_treedepth = 12), chains=6, verbose = FALSE)
View(x)
View(x)
x <- spatial.data[,c("Traffic_volume","Total_vehicles")]
View(x)
x <- pop_plus_accident[,c("Traffic_volume","Total_vehicles")]
View(x)
e <- spatial.data$ExpectedNum
stan.spatial.dataset <- list(N=n, N_edges=n_edges, node1=nod1, node2=nod2, Y=y, X=x, K=length(x), Offset=e)
icar_poisson_fit = stan("stan.stan", data=stan.spatial.dataset, iter=10000, control = list(max_treedepth = 12), chains=6, verbose = FALSE)
pop_plus_accident[7,"ExpectedNum"] <- 2
View(pop_plus_accident)
spatial.data <- merge(London_boro_shp, pop_plus_accident, by.x = "Borough", by.y = "Borough", all.x = TRUE)
sp.object <- as(spatial.data, "Spatial")
adjacencyMatrix <- shape2mat(sp.object)
extractComponents <- prep_icar_data(adjacencyMatrix)
n <- as.numeric(extractComponents$group_size)
nod1 <- extractComponents$node1
nod2 <- extractComponents$node2
n_edges <- as.numeric(extractComponents$n_edges)
y <- spatial.data$Number_of_EV_Fire
x <- pop_plus_accident[,c("Traffic_volume","Total_vehicles")]
e <- spatial.data$ExpectedNum
View(x)
stan.spatial.dataset <- list(N=n, N_edges=n_edges, node1=nod1, node2=nod2, Y=y, X=x, K=length(x), Offset=e)
View(stan.spatial.dataset)
icar_poisson_fit = stan("stan.stan", data=stan.spatial.dataset, iter=10000, control = list(max_treedepth = 12), chains=6, verbose = FALSE)
options(scipen = 999)
summary(icar_poisson_fit, pars=c("alpha", "beta", "sigma"), probs=c(0.025, 0.975))$summary
head(summary(icar_poisson_fit, pars=c("phi"), probs=c(0.025, 0.975))$summary)
# diagnostic check on the rHats - put everything into a data frame
diagnostic.checks <- as.data.frame(summary(icar_poisson_fit, pars=c("alpha", "beta", "sigma", "phi", "lp__"), probs=c(0.025, 0.5, 0.975))$summary)
# create binary variable
diagnostic.checks$valid <- ifelse(diagnostic.checks$Rhat < 1.1, 1, 0)
# tabulate it
table(diagnostic.checks$valid)
head(summary(icar_poisson_fit, pars=c("rr_mu"), probs=c(0.025, 0.975))$summary)
save.image()
summary(icar_poisson_fit, pars=c("alpha", "beta", "sigma"), probs=c(0.025, 0.975))$summary
head(summary(icar_poisson_fit, pars=c("phi"), probs=c(0.025, 0.975))$summary)
View(icar_poisson_fit)
options(scipen = 999)
summary(icar_poisson_fit, pars=c("alpha", "beta", "sigma"), probs=c(0.025, 0.975))$summary
print(icar_poisson_fit)
relativeRisk.results <- as.data.frame(summary(icar_poisson_fit, pars=c("rr_mu"), probs=c(0.025, 0.975))$summary)
library("sf")
library("tmap")
library("spdep")
library("rstan")
library("geostan")
library("SpatialEpi")
library("tidybayes")
library("tidyverse")
library("here")
library("dpl")
relativeRisk.results <- as.data.frame(summary(icar_poisson_fit, pars=c("rr_mu"), probs=c(0.025, 0.975))$summary)
row.names(relativeRisk.results) <- 1:nrow(relativeRisk.results)
View(relativeRisk.results)
relativeRisk.results <- relativeRisk.results[, c(1,4,5,7)]
# third, rename the columns appropriately
colnames(relativeRisk.results)[1] <- "rr"
colnames(relativeRisk.results)[2] <- "rrlower"
colnames(relativeRisk.results)[3] <- "rrupper"
colnames(relativeRisk.results)[4] <- "rHAT"
head(relativeRisk.results)
spatial.data$rr <- relativeRisk.results[, "rr"]
spatial.data$rrlower <- relativeRisk.results[, "rrlower"]
spatial.data$rrupper <- relativeRisk.results[, "rrupper"]
View(spatial.data)
spatial.data$Significance <- NA
spatial.data$Significance[spatial.data$rrlower<1 & spatial.data$rrupper>1] <- 0    # NOT SIGNIFICANT
spatial.data$Significance[spatial.data$rrlower==1 | spatial.data$rrupper==1] <- 0  # NOT SIGNIFICANT
spatial.data$Significance[spatial.data$rrlower>1 & spatial.data$rrupper>1] <- 1    # SIGNIFICANT INCREASE
spatial.data$Significance[spatial.data$rrlower<1 & spatial.data$rrupper<1] <- -1   # SIGNIFICANT DECREASE
View(spatial.data)
summary(spatial.data$rr)
hist(spatial.data$rr)
RiskCategorylist <- c(">0.0 to 0.25", "0.26 to 0.50", "0.51 to 0.75", "0.76 to 0.99", "1.00 & <1.01",
"1.01 to 1.10", "1.11 to 1.25", "1.26 to 1.50", "1.51 to 1.75", "1.76 to 2.00", "2.01 to 3.00")
RRPalette <- c("#65bafe","#98cffe","#cbe6fe","#dfeffe","white","#fed5d5","#fcbba1","#fc9272","#fb6a4a","#de2d26","#a50f15")
spatial.data$RelativeRiskCat <- NA
spatial.data$RelativeRiskCat[spatial.data$rr>= 0 & spatial.data$rr <= 0.25] <- -4
spatial.data$RelativeRiskCat[spatial.data$rr> 0.25 & spatial.data$rr <= 0.50] <- -3
spatial.data$RelativeRiskCat[spatial.data$rr> 0.50 & spatial.data$rr <= 0.75] <- -2
spatial.data$RelativeRiskCat[spatial.data$rr> 0.75 & spatial.data$rr < 1] <- -1
spatial.data$RelativeRiskCat[spatial.data$rr>= 1.00 & spatial.data$rr < 1.01] <- 0
spatial.data$RelativeRiskCat[spatial.data$rr>= 1.01 & spatial.data$rr <= 1.10] <- 1
spatial.data$RelativeRiskCat[spatial.data$rr> 1.10 & spatial.data$rr <= 1.25] <- 2
spatial.data$RelativeRiskCat[spatial.data$rr> 1.25 & spatial.data$rr <= 1.50] <- 3
spatial.data$RelativeRiskCat[spatial.data$rr> 1.50 & spatial.data$rr <= 1.75] <- 4
spatial.data$RelativeRiskCat[spatial.data$rr> 1.75 & spatial.data$rr <= 2.00] <- 5
spatial.data$RelativeRiskCat[spatial.data$rr> 2.00 & spatial.data$rr <= 10] <- 6
View(spatial.data)
table(spatial.data$RelativeRiskCat)
# map of relative risk
rr_map <- tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(england_Region_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of relative risk
rr_map <- tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
tmap_mode("plot")
rr_map <- tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
rr_map <- tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of relative risk
tmap_mode("plot")
tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
tmap_mode("plot")
tm_shape(spatial.data) +
tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05)
tm_shape(spatial.data) +
tm_fill("Significance", style = "cat", title = "Significance Categories",
palette = c("#33a6fe", "white", "#fe0000"), labels = c("Significantly low", "Not Significant", "Significantly high")) +
tm_shape(england_Region_shp) + tm_polygons(alpha = 0.10) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
tm_shape(spatial.data) +
tm_fill("Significance", style = "cat", title = "Significance Categories",
palette = c("#33a6fe", "white", "#fe0000"), labels = c("Significantly low", "Not Significant", "Significantly high")) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.10) + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of significance regions
tm_shape(spatial.data) +
tm_fill("Significance", style = "cat", title = "Significance Categories",
palette = c("#33a6fe", "white", "#fe0000"), labels = c("Significantly low", "Not Significant", "Significantly high")) +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.10) +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
View(relativeRisk.results)
View(spatial.data)
tmap_mode("plot")
tm_shape(spatial.data) +
tm_fill("Number_of_Ev_Fire") +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05)
tmap_mode("plot")
tm_shape(spatial.data) +
tm_fill("Number_of_EV_Fire") +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05)
#Mapping Exceedence probabilities
# extract the exceedence probabilities from the icar_possion_fit object
# compute the probability that an area has a relative risk ratio > 1.0
threshold <- function(x){mean(x > 1.00)}
excProbrr <- icar_poisson_fit %>% spread_draws(rr_mu[i]) %>%
group_by(i) %>% summarise(rr_mu=threshold(rr_mu)) %>%
pull(rr_mu)
# insert the exceedance values into the spatial data frame
spatial.data$excProb <- excProbrr
# categorising the probabilities in bands of 10s
spatial.data$ProbCat <- NA
spatial.data$ProbCat[spatial.data$excProb>=0 & spatial.data$excProb< 0.01] <- 1
spatial.data$ProbCat[spatial.data$excProb>=0.01 & spatial.data$excProb< 0.10] <- 2
spatial.data$ProbCat[spatial.data$excProb>=0.10 & spatial.data$excProb< 0.20] <- 3
spatial.data$ProbCat[spatial.data$excProb>=0.20 & spatial.data$excProb< 0.30] <- 4
spatial.data$ProbCat[spatial.data$excProb>=0.30 & spatial.data$excProb< 0.40] <- 5
spatial.data$ProbCat[spatial.data$excProb>=0.40 & spatial.data$excProb< 0.50] <- 6
spatial.data$ProbCat[spatial.data$excProb>=0.50 & spatial.data$excProb< 0.60] <- 7
spatial.data$ProbCat[spatial.data$excProb>=0.60 & spatial.data$excProb< 0.70] <- 8
spatial.data$ProbCat[spatial.data$excProb>=0.70 & spatial.data$excProb< 0.80] <- 9
spatial.data$ProbCat[spatial.data$excProb>=0.80 & spatial.data$excProb< 0.90] <- 10
spatial.data$ProbCat[spatial.data$excProb>=0.90 & spatial.data$excProb< 1.00] <- 11
spatial.data$ProbCat[spatial.data$excProb == 1.00] <- 12
# check to see if legend scheme is balanced
table(spatial.data$ProbCat)
# map of exceedance probabilities
tm_shape(spatial.data) +
tm_fill("ProbCat", style = "cat", title = "Probability", palette = "PuBu", labels = ProbCategorylist) +
tm_shape(england_Region_shp) + tm_polygons(alpha = 0.05, border.col = "black") + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of exceedance probabilities
tm_shape(spatial.data) +
tm_fill("ProbCat", style = "cat", title = "Probability", palette = "PuBu") +
tm_shape(england_Region_shp) + tm_polygons(alpha = 0.05, border.col = "black") + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of exceedance probabilities
tm_shape(spatial.data) +
tm_fill("ProbCat", style = "cat", title = "Probability", palette = "PuBu") +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05, border.col = "black") + tm_text("name", size = "AREA") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
# map of exceedance probabilities
tm_shape(spatial.data) +
tm_fill("ProbCat", style = "cat", title = "Probability", palette = "PuBu") +
tm_shape(London_boro_shp) + tm_polygons(alpha = 0.05, border.col = "black") +
tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
pop <- read.csv(here::here("Road Casualties Data 2015-2020.csv")) %>% slice(275:307) %>% mutate(LAD21NM = toupper(LAD21NM)) %>% select(LAD21NM,Population)
London_boro_shp <- read_sf(here::here("London_Borough_Excluding_MHW.shp")) %>% mutate(NAME = toupper(NAME)) %>% rename(Borough=NAME)
London_boro_shp <- read_sf(here::here("statistical-gis-boundaries-london","ESRI","London_Borough_Excluding_MHW.shp")) %>% mutate(NAME = toupper(NAME)) %>% rename(Borough=NAME)
